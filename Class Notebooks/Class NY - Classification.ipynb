{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reminders about xgboost: \n",
    "* Uses CPU \n",
    "* More params than scikit-learn\n",
    "* highly performant \n",
    "* gradient-boosted \n",
    "* don't have to worry about missing data! \n",
    "* very resilient at ignoring irrelevant data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working through the Kickstarter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best practice - check your test score and validation score at the beginning to unerstand the relationship between the two of them. Then, you don't use the test score again until the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratify when doing classification\n",
    "\n",
    "For classification problems, it's very important to take **stratified** samples when you're doing your test-training split, esp. if the target condition occurs relatively infrequently. This is particularly common in medical diagnoses problems. If you don't do this, you risk missing all of the \"1s\" in one bucket or another "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding features using summary statistics \n",
    "\n",
    "Such as, how different is this observed value from the average observed value? How many SDs away? \n",
    "\n",
    "**Grouping** is often relevant. For example, for the kickstarter campaigns, the average value raised for the \"Technology\" category may be quite far away from the average value for the \"Haberdashery\" category, so you'd want to take the average within those groups. \n",
    "\n",
    "* **Pro-Tip** - when doing the groupings, be careful to do them only on the training and not the whole dataset. This is a common way that data can \"leak\" into your training set. In class, Jonathan does it by grabbing the ids of the training set rows into a variable, then passing that variable into iloc. This is clever\n",
    "* After creating the grouping, we left join it to the ENTIRE main dataset with df.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often you'll want the probabilities (0.65, 0.22, ...), instead of just the classification labels (0,1,0,0). \n",
    "\n",
    "For that, use **.predict_proba()** instead of just .predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification questions \n",
    "\n",
    "1. Where do you set the cutoff value for classification? Is the default 0.5? \n",
    "2. I'd like to use the cars dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "# suppress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/JonathanBechtel/dat-02-22/main/ClassMaterial/Unit3/data/ks2.csv\", parse_dates = ['deadline', 'launched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370449</th>\n",
       "      <td>999976400</td>\n",
       "      <td>ChknTruk Nationwide Charity Drive 2014 (Canceled)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>2014-09-17 02:35:30</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>50000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370450</th>\n",
       "      <td>999977640</td>\n",
       "      <td>The Tribe</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2011-07-19</td>\n",
       "      <td>2011-06-22 03:35:14</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>1500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370451</th>\n",
       "      <td>999986353</td>\n",
       "      <td>Walls of Remedy- New lesbian Romantic Comedy f...</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2010-08-16</td>\n",
       "      <td>2010-07-01 19:40:30</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>15000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370452</th>\n",
       "      <td>999987933</td>\n",
       "      <td>BioDefense Education Kit</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>2016-01-13 18:13:53</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>15000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370453</th>\n",
       "      <td>999988282</td>\n",
       "      <td>Nou Renmen Ayiti!  We Love Haiti!</td>\n",
       "      <td>Performance Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>USD</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>2011-07-19 09:07:47</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370454 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID                                               name  \\\n",
       "0       1000002330                    The Songs of Adelaide & Abullah   \n",
       "1       1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2       1000004038                                     Where is Hank?   \n",
       "3       1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4       1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "...            ...                                                ...   \n",
       "370449   999976400  ChknTruk Nationwide Charity Drive 2014 (Canceled)   \n",
       "370450   999977640                                          The Tribe   \n",
       "370451   999986353  Walls of Remedy- New lesbian Romantic Comedy f...   \n",
       "370452   999987933                           BioDefense Education Kit   \n",
       "370453   999988282                  Nou Renmen Ayiti!  We Love Haiti!   \n",
       "\n",
       "               category main_category currency   deadline            launched  \\\n",
       "0                Poetry    Publishing      GBP 2015-10-09 2015-08-11 12:12:28   \n",
       "1        Narrative Film  Film & Video      USD 2017-11-01 2017-09-02 04:43:57   \n",
       "2        Narrative Film  Film & Video      USD 2013-02-26 2013-01-12 00:20:50   \n",
       "3                 Music         Music      USD 2012-04-16 2012-03-17 03:24:11   \n",
       "4          Film & Video  Film & Video      USD 2015-08-29 2015-07-04 08:35:03   \n",
       "...                 ...           ...      ...        ...                 ...   \n",
       "370449      Documentary  Film & Video      USD 2014-10-17 2014-09-17 02:35:30   \n",
       "370450   Narrative Film  Film & Video      USD 2011-07-19 2011-06-22 03:35:14   \n",
       "370451   Narrative Film  Film & Video      USD 2010-08-16 2010-07-01 19:40:30   \n",
       "370452       Technology    Technology      USD 2016-02-13 2016-01-13 18:13:53   \n",
       "370453  Performance Art           Art      USD 2011-08-16 2011-07-19 09:07:47   \n",
       "\n",
       "        state country      goal  \n",
       "0           0      GB   1533.95  \n",
       "1           0      US  30000.00  \n",
       "2           0      US  45000.00  \n",
       "3           0      US   5000.00  \n",
       "4           0      US  19500.00  \n",
       "...       ...     ...       ...  \n",
       "370449      0      US  50000.00  \n",
       "370450      0      US   1500.00  \n",
       "370451      0      US  15000.00  \n",
       "370452      0      US  15000.00  \n",
       "370453      0      US   2000.00  \n",
       "\n",
       "[370454 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a variation of what we did previously -- gives us option of getting training / validation / test scores\n",
    "# in a single function\n",
    "def get_model_scores(mod, X_train, y_train, X_test, y_test, val_score = True, test_score=False):\n",
    "    if val_score:\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size = 0.2, \n",
    "                                                          stratify = y_train, \n",
    "                                                          random_state= 42)\n",
    " \n",
    "    mod.fit(X_train, y_train)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['train_score'] = mod.score(X_train, y_train)\n",
    "    if val_score:\n",
    "        results['val_score'] = mod.score(X_val, y_val)\n",
    "        \n",
    "    if test_score:\n",
    "        results['test_score'] = mod.score(X_test, y_test)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to aid in the process\n",
    "def split_data(df, split_frac=0.2, random_state=42):\n",
    "    df = df.drop(['deadline', 'launched'], axis = 1)\n",
    "    X  = df.drop('state', axis=1)\n",
    "    y  = df['state']\n",
    "    # notice the use of 'stratify' -- makes sure y values are in equal proportions in train + test\n",
    "    return train_test_split(X, y, test_size = split_frac, stratify = y, random_state = random_state)\n",
    "\n",
    "# helper function to pull out feature importances_\n",
    "def get_feature_importances(pipe, X_train, onehot=False):\n",
    "    if onehot:\n",
    "        X_train = pipe[0].transform(X_train)\n",
    "        X_train = pipe[1].transform(X_train)\n",
    "    return pd.DataFrame({\n",
    "        'Col': X_train.columns,\n",
    "        'Importance': pipe[-1].feature_importances_\n",
    "    }).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                ID                                               name  \\\n",
       " 317618   723318017                                   City Reflections   \n",
       " 181611  1944996418  Nothin' To Lose Entertainment Album & Album Re...   \n",
       " 195846  2019366381  The Real African History:  As It Relates To Th...   \n",
       " 37117   1192319792                            Ameritocracy: Card Game   \n",
       " 95025   1493261104                          $1 + 10K PEOPLE CHALLENGE   \n",
       " ...            ...                                                ...   \n",
       " 134725  1699214470  Making a horror movie about finding the Founta...   \n",
       " 106564  1553430656                                    The Nightingale   \n",
       " 35971   1186439102                          Double D string stretcher   \n",
       " 6711    1034862045     Visions of Fantastic Realms - Calendar Project   \n",
       " 106672  1553980675                      James for PCT: We Go Together   \n",
       " \n",
       "               category main_category currency country      goal  \n",
       " 317618     Photography   Photography      USD      US    1500.0  \n",
       " 181611         Hip-Hop         Music      USD      US   10000.0  \n",
       " 195846      Nonfiction    Publishing      USD      US  100000.0  \n",
       " 37117   Tabletop Games         Games      USD      US   12500.0  \n",
       " 95025          Hip-Hop         Music      USD      US   10000.0  \n",
       " ...                ...           ...      ...     ...       ...  \n",
       " 134725    Film & Video  Film & Video      USD      US    3300.0  \n",
       " 106564          Design        Design      DKK      DK   36709.1  \n",
       " 35971            Music         Music      USD      US   25000.0  \n",
       " 6711      Illustration           Art      USD      US    5000.0  \n",
       " 106672           Music         Music      USD      US    5000.0  \n",
       " \n",
       " [296363 rows x 7 columns],\n",
       "                 ID                                               name  \\\n",
       " 32126   1166792919           TWiST - Braid Bar (A Natural Hair Salon)   \n",
       " 116502  1604822721                          Cory Bishop's Debut Album   \n",
       " 329951   787596923  \"How to create your own Comic Book\" Workbook a...   \n",
       " 141800  1736168239  Contemporary and Traditional Nepalese Music CD...   \n",
       " 333423   805740436                     Untaken: A book worth the read   \n",
       " ...            ...                                                ...   \n",
       " 198806  2034856586                 What's Going On: America 1969-1974   \n",
       " 184675  1960512450       Atlas Rhoads Full Length Album & Music Video   \n",
       " 62207   1323170321            Art Relish: Documenting Atlanta Artists   \n",
       " 127842  1663322244     Bud & Roo's Spectacular Adventures- The Circus   \n",
       " 328744   781398343                                   Charlie the Cook   \n",
       " \n",
       "                 category main_category currency country      goal  \n",
       " 32126            Fashion       Fashion      USD      US  75000.00  \n",
       " 116502    Country & Folk         Music      USD      US   2500.00  \n",
       " 329951            Comics        Comics      USD      US   4000.00  \n",
       " 141800       World Music         Music      USD      US   2500.00  \n",
       " 333423       Young Adult    Publishing      USD      US   3500.00  \n",
       " ...                  ...           ...      ...     ...       ...  \n",
       " 198806        Photobooks   Photography      USD      US  30000.00  \n",
       " 184675        Indie Rock         Music      USD      US   8950.00  \n",
       " 62207        Documentary  Film & Video      USD      US   7000.00  \n",
       " 127842  Children's Books    Publishing      GBP      GB   1304.74  \n",
       " 328744  Children's Books    Publishing      USD      US   6500.00  \n",
       " \n",
       " [74091 rows x 7 columns],\n",
       " 317618    0\n",
       " 181611    0\n",
       " 195846    0\n",
       " 37117     1\n",
       " 95025     0\n",
       "          ..\n",
       " 134725    1\n",
       " 106564    0\n",
       " 35971     0\n",
       " 6711      0\n",
       " 106672    1\n",
       " Name: state, Length: 296363, dtype: int64,\n",
       " 32126     0\n",
       " 116502    1\n",
       " 329951    0\n",
       " 141800    1\n",
       " 333423    1\n",
       "          ..\n",
       " 198806    1\n",
       " 184675    1\n",
       " 62207     0\n",
       " 127842    0\n",
       " 328744    1\n",
       " Name: state, Length: 74091, dtype: int64]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(pipe, X_val, y_val,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter search\n",
    "estimators = [100, 200, 300, 400]\n",
    "max_depth  = [3, 4]\n",
    "sub_sample = [0.8, 0.6] # this is the amount of samples to randomly sample in each round\n",
    "learning_rate = [0.1, 0.2]\n",
    "cv_scores  = []\n",
    "# do a training loop\n",
    "for estimator in estimators:\n",
    "    for depth in max_depth:\n",
    "        for sample in sub_sample:\n",
    "            for rate in learning_rate:\n",
    "                print(f\"Fitting new training loop for rounds: {estimator}, depth: {depth}, sampling rate: {sample}, rate: {rate}\")\n",
    "                pipe[-1].set_params(n_estimators = estimator,\n",
    "                                    max_depth = depth,\n",
    "                                    subsample = sample,\n",
    "                                    learning_rate = rate)\n",
    "                scores = get_model_scores(pipe, X_train, y_train, X_test, y_test)\n",
    "                cv_scores.append((scores['train_score'], scores['val_score'], estimator, depth, sample, rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
